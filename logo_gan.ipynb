{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"No compatible GPUs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_W = 32\n",
    "IMG_H = 32\n",
    "IMG_C = 1\n",
    "\n",
    "last_epoch = 0\n",
    "batch_size = 128\n",
    "latent_dim = 128\n",
    "SAMPLES_PATH = \"samples_old\"\n",
    "CHECKPOINT_PATH = \"saved_model_old\"\n",
    "LOG_DIR = \"/qarr/studia/magister/models/gan_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not detect any checkpoints to continue from\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    checkpoints = os.listdir(CHECKPOINT_PATH)\n",
    "    last_epoch = np.max([int(re.search(r\"-[0-9]+\\.\", i)[0][1:-1]) for i in checkpoints if\n",
    "                             re.search(r\"-[0-9]+\\.\", i)])\n",
    "    print(\"Detected {} epoch as last checkpoint\".format(last_epoch))\n",
    "except (ValueError,  FileNotFoundError):\n",
    "    last_epoch = 0\n",
    "    print(\"Did not detect any checkpoints to continue from\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_set = np.fromfile('fashion_mnist/train-images-idx3-ubyte', dtype='uint8')\n",
    "learning_lab = np.fromfile('fashion_mnist/train-labels-idx1-ubyte', dtype='uint8')\n",
    "test_set = np.fromfile('fashion_mnist/t10k-images-idx3-ubyte', dtype='uint8')\n",
    "test_lab = np.fromfile('fashion_mnist/t10k-labels-idx1-ubyte', dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = 60000\n",
    "test_examples = 10000\n",
    "batch_size = 128\n",
    "\n",
    "resized_train = np.zeros((train_examples, 32, 32))\n",
    "for i in range(train_examples):\n",
    "    resized_train[i] = cv2.resize(np.reshape(learning_set[16+28*28*i:16+28*28*(i+1)], (28,28,1)), (32, 32))\n",
    "resized_train = np.resize(resized_train, (60000, 32, 32, 1))\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(resized_train)\n",
    "def normalize(images):\n",
    "  images = tf.cast(images, tf.float32)\n",
    "  images /= 255\n",
    "  return images\n",
    "\n",
    "train_dataset =  train_dataset.map(normalize)\n",
    "train_dataset = train_dataset.cache().repeat().shuffle(train_examples).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f62701f8790>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset.as_numpy_iterator().next()[0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([372.,  15.,  38.,  20.,  46.,  62., 192., 174.,  71.,  34.]),\n",
       " array([0.        , 0.08392157, 0.16784313, 0.2517647 , 0.33568627,\n",
       "        0.41960785, 0.5035294 , 0.587451  , 0.67137253, 0.75529414,\n",
       "        0.8392157 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.ravel(train_dataset.as_numpy_iterator().next()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common helper functions and clearing session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons import *\n",
    "weight_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(examples, epoch, n):\n",
    "    examples = (examples + 1) / 2.0\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(examples[i])\n",
    "    if not os.path.exists(SAMPLES_PATH):\n",
    "        os.mkdir(SAMPLES_PATH)\n",
    "    filename = f\"{SAMPLES_PATH}/generated_plot_epoch-{epoch+1}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "checkpoint_path_g = f\"{CHECKPOINT_PATH}/gencp-{{epoch:02d}}.ckpt\"\n",
    "checkpoint_path_d = f\"{CHECKPOINT_PATH}/discp-{{epoch:02d}}.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path_g)\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = LOG_DIR, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = build_discriminator_ref(weight_init, IMG_H=IMG_H, IMG_W=IMG_W, IMG_C=IMG_C)\n",
    "g_model = build_generator_ref(latent_dim, weight_init, IMG_H=IMG_H, IMG_W=IMG_W, IMG_C=IMG_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model from last checkpoint, if able"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint to load from\n"
     ]
    }
   ],
   "source": [
    "if last_epoch:\n",
    "    d_model.load_weights(checkpoint_path_d.format(epoch=last_epoch))\n",
    "    g_model.load_weights(checkpoint_path_g.format(epoch=last_epoch))\n",
    "    print(f\"Loading models from epoch {last_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint to load from\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_noise_input (Input [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 32)        51200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 1)         0         \n",
      "=================================================================\n",
      "Total params: 4,625,057\n",
      "Trainable params: 4,620,001\n",
      "Non-trainable params: 5,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_old(tf.keras.models.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN_old, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN_old, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        for _ in range(2):\n",
    "            ## Train the discriminator\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            generated_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as ftape:\n",
    "                predictions = self.discriminator(generated_images)\n",
    "                d1_loss = self.loss_fn(generated_labels, predictions)\n",
    "            grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "            ## Train the discriminator\n",
    "            labels = tf.ones((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as rtape:\n",
    "                predictions = self.discriminator(real_images)\n",
    "                d2_loss = self.loss_fn(labels, predictions)\n",
    "            grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        ## Train the generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as gtape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        return {\"d1_loss\": d1_loss, \"d2_loss\": d2_loss, \"g_loss\": g_loss, \"total\":d1_loss+d2_loss+g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for = 200 # epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN_old(d_model, g_model, latent_dim)\n",
    "bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "gan.compile(d_optimizer, g_optimizer, bce_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 87s 186ms/step - d1_loss: 0.2216 - d2_loss: 0.2620 - g_loss: 2.4082 - total: 2.8919\n",
      "Epoch 2/2\n",
      "468/468 [==============================] - 88s 189ms/step - d1_loss: 0.2277 - d2_loss: 0.2370 - g_loss: 2.5942 - total: 3.0589\n",
      "Epoch 3/3\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2283 - d2_loss: 0.2448 - g_loss: 2.5924 - total: 3.0655\n",
      "Epoch 4/4\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2285 - d2_loss: 0.2525 - g_loss: 2.5029 - total: 2.9840\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2323 - d2_loss: 0.2498 - g_loss: 2.5899 - total: 3.0719\n",
      "Epoch 6/6\n",
      "468/468 [==============================] - 88s 189ms/step - d1_loss: 0.2416 - d2_loss: 0.2459 - g_loss: 2.6625 - total: 3.1499\n",
      "Epoch 7/7\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2393 - d2_loss: 0.2476 - g_loss: 2.5845 - total: 3.0714\n",
      "Epoch 8/8\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2453 - d2_loss: 0.2496 - g_loss: 2.6222 - total: 3.1170\n",
      "Epoch 9/9\n",
      "468/468 [==============================] - 88s 189ms/step - d1_loss: 0.2454 - d2_loss: 0.2545 - g_loss: 2.5626 - total: 3.0625\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2457 - d2_loss: 0.2614 - g_loss: 2.5342 - total: 3.0413\n",
      "Epoch 11/11\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2415 - d2_loss: 0.2663 - g_loss: 2.5041 - total: 3.0119\n",
      "Epoch 12/12\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2427 - d2_loss: 0.2672 - g_loss: 2.5028 - total: 3.0127\n",
      "Epoch 13/13\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2397 - d2_loss: 0.2698 - g_loss: 2.4818 - total: 2.9913\n",
      "Epoch 14/14\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2378 - d2_loss: 0.2716 - g_loss: 2.4757 - total: 2.9851\n",
      "Epoch 15/15\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2369 - d2_loss: 0.2731 - g_loss: 2.4697 - total: 2.9797\n",
      "Epoch 16/16\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2366 - d2_loss: 0.2738 - g_loss: 2.4902 - total: 3.0006\n",
      "Epoch 17/17\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2374 - d2_loss: 0.2760 - g_loss: 2.4699 - total: 2.9833\n",
      "Epoch 18/18\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2354 - d2_loss: 0.2685 - g_loss: 2.4994 - total: 3.0032\n",
      "Epoch 19/19\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2358 - d2_loss: 0.2747 - g_loss: 2.4989 - total: 3.0094\n",
      "Epoch 20/20\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2346 - d2_loss: 0.2710 - g_loss: 2.4992 - total: 3.0048\n",
      "Epoch 21/21\n",
      "468/468 [==============================] - 88s 187ms/step - d1_loss: 0.2340 - d2_loss: 0.2681 - g_loss: 2.5241 - total: 3.0262\n",
      "Epoch 22/22\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2327 - d2_loss: 0.2656 - g_loss: 2.5225 - total: 3.0208\n",
      "Epoch 23/23\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2330 - d2_loss: 0.2672 - g_loss: 2.5333 - total: 3.0335\n",
      "Epoch 24/24\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2342 - d2_loss: 0.2692 - g_loss: 2.5251 - total: 3.0285\n",
      "Epoch 25/25\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2321 - d2_loss: 0.2591 - g_loss: 2.5853 - total: 3.0766\n",
      "Epoch 26/26\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2346 - d2_loss: 0.2654 - g_loss: 2.5503 - total: 3.0503\n",
      "Epoch 27/27\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2322 - d2_loss: 0.2569 - g_loss: 2.5954 - total: 3.0845\n",
      "Epoch 28/28\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2479 - d2_loss: 0.2986 - g_loss: 2.4519 - total: 2.9983\n",
      "Epoch 29/29\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2328 - d2_loss: 0.2602 - g_loss: 2.5792 - total: 3.0723\n",
      "Epoch 30/30\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2351 - d2_loss: 0.2585 - g_loss: 2.6251 - total: 3.1187\n",
      "Epoch 31/31\n",
      "468/468 [==============================] - 88s 189ms/step - d1_loss: 0.2340 - d2_loss: 0.2552 - g_loss: 2.6263 - total: 3.1155\n",
      "Epoch 32/32\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2321 - d2_loss: 0.2551 - g_loss: 2.6139 - total: 3.1011\n",
      "Epoch 33/33\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2312 - d2_loss: 0.2451 - g_loss: 2.6989 - total: 3.1751\n",
      "Epoch 34/34\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2335 - d2_loss: 0.2488 - g_loss: 2.6746 - total: 3.1569\n",
      "Epoch 35/35\n",
      "468/468 [==============================] - 89s 190ms/step - d1_loss: 0.2318 - d2_loss: 0.2435 - g_loss: 2.7151 - total: 3.1904\n",
      "Epoch 36/36\n",
      "468/468 [==============================] - 89s 189ms/step - d1_loss: 0.2319 - d2_loss: 0.2401 - g_loss: 2.7453 - total: 3.2173\n",
      "Epoch 37/37\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2326 - d2_loss: 0.2417 - g_loss: 2.7473 - total: 3.2216\n",
      "Epoch 38/38\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2333 - d2_loss: 0.2374 - g_loss: 2.7732 - total: 3.2439\n",
      "Epoch 39/39\n",
      "468/468 [==============================] - 88s 187ms/step - d1_loss: 0.2328 - d2_loss: 0.2359 - g_loss: 2.7949 - total: 3.2636\n",
      "Epoch 40/40\n",
      "468/468 [==============================] - 88s 187ms/step - d1_loss: 0.2325 - d2_loss: 0.2330 - g_loss: 2.8248 - total: 3.2903\n",
      "Epoch 41/41\n",
      "468/468 [==============================] - 88s 188ms/step - d1_loss: 0.2320 - d2_loss: 0.2299 - g_loss: 2.8449 - total: 3.3068\n",
      "Epoch 42/42\n",
      "468/468 [==============================] - 89s 190ms/step - d1_loss: 0.2311 - d2_loss: 0.2290 - g_loss: 2.8522 - total: 3.3123\n",
      "Epoch 43/43\n",
      " 78/468 [====>.........................] - ETA: 1:13 - d1_loss: 0.2327 - d2_loss: 0.2263 - g_loss: 2.8512 - total: 3.3102"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f7b0d9c29d9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtrain_for\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     gan.fit(train_dataset, \n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 25\n",
    "noise = np.random.normal(size=(n_samples, latent_dim))\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "try:\n",
    "    for epoch in range(last_epoch, last_epoch+train_for):\n",
    "        gan.fit(train_dataset, \n",
    "                initial_epoch=epoch, \n",
    "                epochs=epoch+1, \n",
    "                batch_size=batch_size, \n",
    "                steps_per_epoch=train_examples//batch_size,\n",
    "                callbacks=[tboard_callback]\n",
    "               )\n",
    "        g_model.save_weights(checkpoint_path_g.format(epoch=epoch+1))\n",
    "        d_model.save_weights(checkpoint_path_d.format(epoch=epoch+1))\n",
    "\n",
    "        n_samples = 25\n",
    "        new_noise = np.random.normal(size=(n_samples, latent_dim))\n",
    "        new_noise[0:5] = noise[0:5]\n",
    "        examples = g_model.predict(new_noise)\n",
    "        save_plot(examples, epoch, int(np.sqrt(n_samples)))\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "    \n",
    "last_epoch += train_for\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
