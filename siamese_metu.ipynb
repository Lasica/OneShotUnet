{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "from commons import *\n",
    "from gan_arch import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"No compatible GPUs found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATETIME =  datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "METU_RAW_PATH = '/qarr/studia/magister/datasets/METU/930k_logo_v3/'\n",
    "METU_DATASET_PATH = '/home/zenfur/magister/resized_930k_logo/'\n",
    "EVAL_ORIGIN_PATH = '/qarr/studia/magister/datasets/METU/query_reversed/'\n",
    "EVAL_DATASET_PATH = '/home/zenfur/magister/metu_eval_256sq/'\n",
    "LOG_DIR = \"siamese_logs/\" + DATETIME\n",
    "MODEL_SAVE_NAME = \"siamese_model\" + DATETIME\n",
    "LOAD = True\n",
    "LAST_MODEL = \"/home/zenfur/magister/jupyter/siamese_model20210322-032225_1560/\"\n",
    "TESTING=False\n",
    "    \n",
    "last_epoch=0\n",
    "#tf.debugging.experimental.enable_dump_debug_info(\"siamese_logs/\", tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset pipeline and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesList = tf.io.matching_files(EVAL_DATASET_PATH + \"*.jpg\")\n",
    "\n",
    "@tf.function\n",
    "def tf_get_filename(path):\n",
    "    return tf.strings.regex_replace(path, \"[^/]*/\", \"\")\n",
    "\n",
    "\n",
    "#@tf.function\n",
    "def tf_read_image(path):\n",
    "    # Retrieving the group number from file name\n",
    "    img = tf.io.read_file(path)\n",
    "    return tf.image.decode_jpeg(img, channels=3, dct_method='INTEGER_ACCURATE')\n",
    "\n",
    "\n",
    "def tf_get_class_from_name(path):\n",
    "    filename = tf_get_filename(path)\n",
    "    group_number = tf.strings.to_number(\n",
    "        tf.strings.regex_replace(filename, \"-.*$\", \"\"), \n",
    "        out_type=tf.dtypes.int32\n",
    "    )\n",
    "    return group_number\n",
    "\n",
    "#@tf.function\n",
    "def tf_convert_and_normalize_img(img):\n",
    "    c = tf.constant(256.0, dtype=tf.dtypes.float32)\n",
    "    img = tf.cast(img, tf.dtypes.float32)\n",
    "    return tf.math.divide(img, c)\n",
    "\n",
    "\n",
    "evalpathsDB = tf.data.Dataset.from_tensor_slices(imagesList)\n",
    "\n",
    "DBlen = len(imagesList)\n",
    "\n",
    "evalDB = (      evalpathsDB.map(tf_read_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                 .batch(32)\n",
    "                 .map(tf_convert_and_normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "evalGrps = (      evalpathsDB.map(tf_get_class_from_name, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "                   .batch(32)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting and preparing images into groups by name\n",
    "By convention, discarding images from group 0, as they have been manually inserted as the examples that differ from the rest sampled from 930k METU dataset.\n",
    "\n",
    "Reordering the labels from alphabetical order into ascending by group number order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = np.array(list(evalGrps.unbatch().as_numpy_iterator()))\n",
    "labsOrder = np.argsort(labs)\n",
    "labs = labs[labsOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGroupsDct = dict()\n",
    "for i, l in enumerate(labs):\n",
    "    last_count = imageGroupsDct.get(l,(i,0))\n",
    "    imageGroupsDct[l] = (last_count[0], last_count[1] + 1)\n",
    "del(imageGroupsDct[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom triples sampler based on linear congruent generator \n",
    "The generator has period equal NumberOfUnlikeSamples*(NumberOfAlikeSamples-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_generator(start, length, avoid, n, initial, prime=756212269):\n",
    "    \"\"\"\n",
    "    results in sequence of triplets (<start:start+length>, <avoid>, <0:n-1 excluding start:start+length-1>)\n",
    "    \"\"\"\n",
    "    start = np.array(start, dtype=np.int32)\n",
    "    length = np.array(length, dtype=np.int32)\n",
    "    avoid = np.array(avoid, dtype=np.int32)\n",
    "    initial = np.array(initial, dtype=np.int32)\n",
    "    current = initial\n",
    "    unlikeCount = (n-length)\n",
    "    length = length - 1\n",
    "    modulo_base = length * unlikeCount\n",
    "    multiplier = modulo_base*11*3+1\n",
    "    while True:\n",
    "        # Generating next modulo from sequence\n",
    "        current = (multiplier * current + prime) % modulo_base\n",
    "        like = (current % length)\n",
    "        unlike = current // length\n",
    "        \n",
    "        # Calculating proper indices from random modulos\n",
    "        like += start\n",
    "        like += (like >= avoid)\n",
    "        like = np.expand_dims(like, axis=1)\n",
    "        \n",
    "        unlike = unlike + ((unlike >= start) * (length+1))\n",
    "        unlike = np.expand_dims(unlike, axis=1)\n",
    "        \n",
    "        for triplet in np.concatenate((like, np.expand_dims(avoid, axis=1), unlike), axis=1):\n",
    "            yield triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    gen = triplet_generator(starts, lengths, avoids, len(labs), seeds)\n",
    "    # Test: group 1:3, n=6, x = 2\n",
    "    g = triplet_generator([1], [3], [2], 6, [423432231])\n",
    "    s = set()\n",
    "    for i in range(2*3):\n",
    "        t = next(g)\n",
    "        print(t)\n",
    "        if tuple(t) in s:\n",
    "            break\n",
    "        else:\n",
    "            s.add(tuple(t))\n",
    "    assert i == (2*3)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    for i in range(10):\n",
    "        print(next(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into validation and training subsets\n",
    "\n",
    "Taking **validationUniques** samples from each class as uniqiue anchor samples in validation dataset. Pairing those with **xSamples** random samples from original class as alike sample and any other class as unlike sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationUniques = 2\n",
    "validationSubset = [(a, [i for i in range(j[0],j[0] + validationUniques)]) for a,j in imageGroupsDct.items()]\n",
    "validationSamples = []\n",
    "xSamples = 40\n",
    "N = len(labs)\n",
    "np.random.seed(14200)\n",
    "for grp, samples in validationSubset:\n",
    "    for sample in samples:\n",
    "        groupStart =  imageGroupsDct[grp][0]\n",
    "        groupLength = imageGroupsDct[grp][1]\n",
    "        for i in range(xSamples):\n",
    "            alike = np.random.randint(groupStart, groupStart + groupLength)\n",
    "            unlike = np.random.randint(0, N-groupLength)\n",
    "            unlike += (unlike>=groupStart)*groupLength\n",
    "            validationSamples.append((alike, sample, unlike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingTranslationTable = np.array(range(N-validationUniques*len(validationSubset)))\n",
    "starts = [s[0] for s in imageGroupsDct.values()]\n",
    "starts.sort()\n",
    "starts.append(N+1)\n",
    "j = 0\n",
    "for i in range(len(trainingTranslationTable)):\n",
    "    if starts[j] <= i+j*validationUniques:\n",
    "        j += 1\n",
    "    trainingTranslationTable[i] = i+j*validationUniques\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGroups = list(imageGroupsDct.items())\n",
    "avoids, starts, lengths, seeds = [], [], [], []\n",
    "\n",
    "# Generating the random seeds for custom random sequence generators that iterate over triplets from each group\n",
    "# For the sake of being repeatable, fixing seed\n",
    "np.random.seed(949127843)\n",
    "for igrp in imageGroups:\n",
    "    for i in range(igrp[1][1] - validationUniques):\n",
    "        avoids.append(i+igrp[1][0] - (igrp[0]-1)*validationUniques)\n",
    "        starts.append(igrp[1][0] - (igrp[0]-1)*validationUniques)\n",
    "        lengths.append(igrp[1][1] - validationUniques)\n",
    "        seeds.append(np.random.randint(0, high=10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLength = len(trainingTranslationTable)\n",
    "validSamples = N - trainLength\n",
    "validLength = len(validationSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validLength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the pipeline segments \n",
    "\n",
    "Converting the database of samples into numpy array, since it can fit into RAM memory to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesTable = tf_db_to_array(evalDB, DBlen)\n",
    "imagesTable = imagesTable[labsOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesTable = tf.constant(imagesTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingTranslationTable = tf.constant(trainingTranslationTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_by_index(triplet):\n",
    "    # @triplet: tuple/tensor of indices in the images table\n",
    "    return tf.gather(imagesTable, triplet)\n",
    "\n",
    "\n",
    "def translate_indices(triplet):\n",
    "    return tf.gather(trainingTranslationTable, triplet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the common source of random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = tf.random.Generator.from_seed(41431)\n",
    "rngValid = tf.random.Generator.from_seed(198489)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the data augmentation functions for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_slice_224x224(image, seed):\n",
    "    return tf.image.stateless_random_crop(image, [224,224,3], seed)\n",
    "\n",
    "\n",
    "def get_center_slice(image):\n",
    "    return tf.image.central_crop(image, 224/256)\n",
    "\n",
    "\n",
    "def random_rotate(image, seed):\n",
    "    if seed > 3:\n",
    "        seed = 0\n",
    "    return tf.image.rot90(image, k=seed)\n",
    "\n",
    "\n",
    "def static_augment(image, seeds):\n",
    "    sditer = iter(seeds)\n",
    "    \n",
    "    image = random_slice_224x224(image, next(sditer))\n",
    "    image = random_rotate(image, next(sditer))\n",
    "    \n",
    "    return image\n",
    "    \n",
    "    \n",
    "def augment(image):\n",
    "    seeds = [rng.make_seeds(2)[0], rng.uniform([], minval=0, maxval=5, dtype=tf.int32)]\n",
    "    return static_augment(image, seeds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input data pipeline\n",
    "\n",
    "Defining the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 4\n",
    "trainDset = tf.data.Dataset.from_generator(triplet_generator,\n",
    "                                    args = [starts, lengths, avoids, trainLength, seeds],\n",
    "                                    output_signature=tf.TensorSpec(shape=(3), dtype=tf.int32))\n",
    "\n",
    "trainDset = (trainDset.shuffle(trainLength)\n",
    "      .map(translate_indices, num_parallel_calls=AUTOTUNE, deterministic=True)\n",
    "      .map(get_triplet_by_index)\n",
    "      .unbatch()\n",
    "# unbatching to augment images individually, as its difficult to make a parallel function for it\n",
    "# TODO: possible improvement\n",
    "      .map(augment, num_parallel_calls=AUTOTUNE, deterministic=True)\n",
    "      .batch(3*BATCH_SIZE)\n",
    "      .prefetch(2)#AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing augmentation seeds for validation d-set or disabling it alltogether\n",
    "\n",
    "# validRandoms = []\n",
    "# for s in range(validLength):\n",
    "#     validRandoms.append([rng.make_seeds(2)[0], rng.uniform([], minval=0, maxval=5, dtype=tf.int32)])\n",
    "\n",
    "validDset = (tf.data.Dataset.from_tensor_slices(validationSamples)\n",
    "                .repeat()\n",
    "                .map(get_triplet_by_index)\n",
    "                .unbatch()\n",
    "                .map(get_center_slice) # disabling augmentation\n",
    "                .batch(3*BATCH_SIZE)\n",
    "                .prefetch(2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = validDset.take(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = next(iter(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(g[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling and testing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    img = get_triplet_by_index(tf.constant(next(triplet_generator(starts, lengths, avoids, len(labs), seeds))))\n",
    "    f, subplots = plt.subplots(1,3)\n",
    "    for i, sb in enumerate(subplots):\n",
    "        sb.imshow(img[i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TESTING:\n",
    "#     img = df.take(1)\n",
    "#     img = next(iter(img))\n",
    "#     f, subplots = plt.subplots(1,3)\n",
    "#     for i, sb in enumerate(subplots):\n",
    "#         sb.imshow(img[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese model\n",
    "\n",
    "Importing the  pre-trained VGG16 model with weights from imagenet without classification part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding 2 dense layers on top of convolutions for 4096 representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "    siamese_base = tf.keras.models.load_model(LAST_MODEL)\n",
    "else:\n",
    "    vgg16 = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3),\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "    )\n",
    "    #vgg16.trainable = False\n",
    "    siamese_base = tf.keras.models.Sequential()\n",
    "    for layer in (vgg16,\n",
    "                    tf.keras.layers.Flatten(),\n",
    "                    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "                    tf.keras.layers.Dense(4096, activation='relu')\n",
    "                 ):\n",
    "        siamese_base.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(vgg16, \"vgg16-base.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(siamese_base, \"siamese.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese triplet loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(alike, anchor, unlike, margin=1.0, reduce=tf.reduce_mean):\n",
    "    a = tf.norm(alike-anchor, axis=1)\n",
    "    b = tf.norm(unlike-anchor, axis=1)\n",
    "    return reduce(tf.maximum(a + margin - b, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    try:\n",
    "        return f'{x.shape}'\n",
    "    except AttributeError:\n",
    "        return f\"{'[' + ', '.join([describe(q) for q in x]) + ']'}\"\n",
    "    \n",
    "class TripletSiamese(tf.keras.models.Model):\n",
    "    def __init__(self, shared_net, name=None):\n",
    "        super(TripletSiamese, self).__init__(name=name)\n",
    "        self.siamese_base = shared_net\n",
    "        self.callctr = 0\n",
    "\n",
    "    def compile(self, optimizer, loss_margin):\n",
    "        super(TripletSiamese, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = triplet_loss#lambda a,b,c: triplet_loss(a,b,c, margin=loss_margin)\n",
    "    \n",
    "    def normalize_output(self, x):\n",
    "        return x / tf.expand_dims(tf.maximum(tf.math.reduce_max(x, axis=1), 1e-5), axis=1)\n",
    "    \n",
    "    @tf.function#(jit_compile=True)\n",
    "    def train_step(self, input_triplets):\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # training and calculating the error function gradient\n",
    "            representations = self.siamese_base(input_triplets, training=True)\n",
    "            representations = self.normalize_output(representations)\n",
    "            alike = tf.strided_slice(representations, [0,0], tf.shape(representations), strides=[3,1])\n",
    "            anchor = tf.strided_slice(representations, [1,0], tf.shape(representations), strides=[3,1])\n",
    "            unlike = tf.strided_slice(representations, [2,0], tf.shape(representations), strides=[3,1])\n",
    "            loss = self.loss(alike, anchor, unlike)\n",
    "        grads = tape.gradient(loss, self.siamese_base.trainable_weights)\n",
    "\n",
    "        \n",
    "#         alike_in = tf.strided_slice(input_triplets, [0,0,0,0], tf.shape(input_triplets), strides=[3,1,1,1])\n",
    "#         anchor_in = tf.strided_slice(input_triplets, [1,0,0,0], tf.shape(input_triplets), strides=[3,1,1,1])\n",
    "#         unlike_in = tf.strided_slice(input_triplets, [2,0,0,0], tf.shape(input_triplets), strides=[3,1,1,1])\n",
    "\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             alike = self.siamese_base(alike_in, training=True)\n",
    "#         grads1 = tape.gradient(alike, self.siamese_base.trainable_weights) \n",
    "        \n",
    "#         with tf.GradientTape() as tape:\n",
    "#             anchor = self.siamese_base(anchor_in, training=True)\n",
    "#         grads2 = tape.gradient(anchor, self.siamese_base.trainable_weights) \n",
    "        \n",
    "#         with tf.GradientTape() as tape:\n",
    "#             unlike = self.siamese_base(unlike_in, training=True)\n",
    "#         grads3 = tape.gradient(unlike, self.siamese_base.trainable_weights) \n",
    "        \n",
    "#         tf.print(describe(grads1))\n",
    "#         tf.print(describe(alike))\n",
    "#         tf.print(describe(anchor))\n",
    "#         grads1 *= 2*(alike - anchor)\n",
    "#         grads2 *= 2*(unlike - alike)\n",
    "#         grads3 *= 2*(alike - unlike)\n",
    "        \n",
    "#         grads = np.mean([grads1, grads2, grads3])# ...\n",
    "\n",
    "#         loss = self.loss(alike, anchor, unlike)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.siamese_base.trainable_weights))\n",
    "        \n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "        \n",
    "    def evaluate(self, x=None, y=None, batch_size=None, verbose=False, sample_weight=None, steps=None,\n",
    "                callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False,\n",
    "                return_dict=False):\n",
    "        r = self.siamese_base.predict(x=x, batch_size=batch_size, verbose=False, steps=steps, callbacks=callbacks)\n",
    "        r = self.normalize_output(r)\n",
    "        alike = tf.strided_slice(r, [0,0], tf.shape(r), strides=[3,1])\n",
    "        anchor = tf.strided_slice(r, [1,0], tf.shape(r), strides=[3,1])\n",
    "        unlike = tf.strided_slice(r, [2,0], tf.shape(r), strides=[3,1])\n",
    "        dct = {\"loss\":self.loss(alike, anchor, unlike, reduce=tf.reduce_mean)}\n",
    "        if callbacks is not None:\n",
    "            for cb in callbacks:\n",
    "                cb.on_test_batch_end(x, logs=dct)\n",
    "        if return_dict:\n",
    "            return dct\n",
    "        else:\n",
    "            return dct[\"loss\"]\n",
    "\n",
    "\n",
    "#     def __call__(self, x, training=False):\n",
    "#         representations = self.siamese_base(x, training=training)\n",
    "#         representations = self.normalize_output(representations)\n",
    "#         alike = tf.strided_slice(representations, [0,0], tf.shape(representations), strides=[3,1])\n",
    "#         anchor = tf.strided_slice(representations, [1,0], tf.shape(representations), strides=[3,1])\n",
    "#         unlike = tf.strided_slice(representations, [2,0], tf.shape(representations), strides=[3,1])\n",
    "#         return self.loss(alike, anchor, unlike)\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.siamese_base.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = TripletSiamese(siamese_base, name=MODEL_SAVE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "triplet_model.compile(opt, triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet_model.train_step(tf.image.central_crop(img, 224/256))\n",
    "# #siamese_base(tf.image.central_crop(img, 224/256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the training with hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTBCallback(tf.keras.callbacks.TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MeanTBCallback, self).__init__(*args, **kwargs)\n",
    "        self._epoch = 1\n",
    "        self.mean_train_loss = 0\n",
    "        self.mean_test_loss = 0\n",
    "        self.train_batches = 0\n",
    "        self.test_batches = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super(MeanTBCallback, self).on_epoch_end(epoch, logs=logs)\n",
    "        # Tensorflow 2.2.0 breaks compatibility here\n",
    "        writer = self._train_writer\n",
    "        \n",
    "        if self.train_batches > 0:\n",
    "            with self._train_writer.as_default():\n",
    "                tf.summary.scalar(\"mean_loss\", self.mean_train_loss/self.train_batches, step = self._epoch)\n",
    "\n",
    "        if self.test_batches > 0:\n",
    "            tf.print(f\"Mean losses: train:{self.mean_train_loss/self.train_batches} val:{self.mean_test_loss/self.test_batches}\")\n",
    "            with self._val_writer.as_default():\n",
    "                tf.summary.scalar(\"mean_loss\", self.mean_test_loss/self.test_batches, step = self._epoch)\n",
    "\n",
    "        self._epoch += 1\n",
    "        self.train_batches = 0\n",
    "        self.test_batches = 0\n",
    "        self.mean_train_loss = 0\n",
    "        self.mean_test_loss = 0\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.train_batches += 1\n",
    "        if \"loss\" in logs:\n",
    "            self.mean_train_loss += logs[\"loss\"]\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        self.test_batches += 1\n",
    "        if \"loss\" in logs:\n",
    "            self.mean_test_loss += logs[\"loss\"]\n",
    "  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tboard_callback = MeanTBCallback(log_dir = \"/tmp/tflogs\", histogram_freq=5, profile_batch=0) #LOG_DIR\n",
    "\n",
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(MODEL_SAVE_NAME + \"/{epoch:02d}-{loss:.2f}-siamese\", \n",
    "#                                                          monitor=\"loss\", save_best_only=True)\n",
    "# tf.debugging.experimental.enable_dump_debug_info(\n",
    "#     \"/tmp/tfdbg2_logdir\", tensor_debug_mode=\"FULL_HEALTH\",\n",
    "#     circular_buffer_size=1000, op_regex=None, tensor_dtypes=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs to train\n",
    "train_for = 1600\n",
    "validation_interval = 10\n",
    "save_interval = 120\n",
    "try:\n",
    "    for i in range(last_epoch, last_epoch+train_for):\n",
    "        validation = {}\n",
    "        if last_epoch % validation_interval == 0:\n",
    "            validation = {\n",
    "                \"validation_data\":validDset,\n",
    "                \"validation_steps\":2,#validLength//BATCH_SIZE, \n",
    "                \"validation_batch_size\":BATCH_SIZE\n",
    "            }\n",
    "        else:\n",
    "            validation = {\n",
    "                \"validation_data\":None,\n",
    "                \"validation_steps\":None, \n",
    "                \"validation_batch_size\":None\n",
    "            }\n",
    "        triplet_model.fit(trainDset, \n",
    "                      initial_epoch=last_epoch,\n",
    "                      epochs=last_epoch+1,\n",
    "                      steps_per_epoch=2,#trainLength//BATCH_SIZE,\n",
    "                      callbacks=[tboard_callback],#, checkpoint_callback]\n",
    "                      **validation\n",
    "                     ) # batch_size unspecified since it's generated by generator\n",
    "        last_epoch += 1\n",
    "        \n",
    "        if last_epoch%save_interval == 0:\n",
    "            if MODEL_SAVE_NAME is not None:\n",
    "                siamese_base.save(MODEL_SAVE_NAME + \"_\" + str(last_epoch))\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Interrupted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# if MODEL_SAVE_NAME is not None:\n",
    "#     siamese_base.save(MODEL_SAVE_NAME + \"_\" + str(last_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprs = siamese_base.predict(tf.image.central_crop(imagesTable, 224/256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_reps = reprs / tf.expand_dims(tf.maximum(tf.math.reduce_max(reprs, axis=1), 1e-7), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_images = [v for a in [vv[1] for vv in validationSubset] for v in a]\n",
    "fig, plots = plt.subplots(len(selected_images), 6, figsize=(110/12/2,130*len(selected_images)/72/2))\n",
    "for i, selected in enumerate(selected_images):\n",
    "    img = norm_reps[selected]\n",
    "    dist = lambda x: tf.sqrt(tf.reduce_sum((x - img)**2))\n",
    "    reprs_distance = tf.map_fn(dist, norm_reps)\n",
    "    closest_idx = np.argsort(reprs_distance)\n",
    "    for j, p in enumerate(closest_idx[0:6]):\n",
    "        plots[i][j].imshow(imagesTable[p].numpy())\n",
    "        if j == 0:\n",
    "            plots[i][j].set_title(f\"{p}\", fontsize=7)\n",
    "        else:\n",
    "            plots[i][j].set_title(f\"{reprs_distance[p]:2.3}\", fontsize=7)\n",
    "        plots[i][j].axes.get_xaxis().set_visible(False)\n",
    "        plots[i][j].axes.get_yaxis().set_visible(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(np.ravel(reprs)[np.ravel(reprs) != 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {\n",
    "    \"validation_data\":validDset,\n",
    "    \"validation_steps\":validLength//BATCH_SIZE, \n",
    "    \"validation_batch_size\":BATCH_SIZE\n",
    "}\n",
    "triplet_model.fit(trainDset, \n",
    "              epochs=1,\n",
    "              steps_per_epoch=1,\n",
    "              **validation\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.evaluate(validDset, steps=validLength//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for y in a for x in y]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
