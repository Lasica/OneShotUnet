{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "LInputTarget = tf.keras.Input(dtype = tf.float32, shape = [256, 256, 3], name = 'Target')\n",
    "with tf.name_scope(\"Encoder\"):\n",
    "    Lconv1_1 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LInputTarget) \n",
    "    Lconv1_2 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lconv1_1) \n",
    "    Lpool1 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(Lconv1_2)\n",
    "\n",
    "    Lconv2_1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lpool1) \n",
    "    Lconv2_2 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lconv2_1) \n",
    "    Lpool2 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(Lconv2_2)\n",
    "\n",
    "    Lconv3_1 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lpool2) \n",
    "    Lconv3_2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lconv3_1) \n",
    "    Lpool3 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(Lconv3_2)\n",
    "\n",
    "    Lconv4_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lpool3) \n",
    "    Lconv4_2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lconv4_1) \n",
    "    Lpool4 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(Lconv4_2)\n",
    "\n",
    "    Lconv5_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lpool4) \n",
    "    Lconv5_2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(Lconv5_1) \n",
    "    Lpool5 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(Lconv5_2)\n",
    "    \n",
    "    modelEncoder = tf.keras.Model(inputs=LInputTarget, outputs=Lpool5, name=\"Unet model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEncoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(modelEncoder, \"unet_encoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LInputQuery  = tf.keras.Input(dtype = tf.float32, shape = [64, 64, 3], name = 'Query')\n",
    "with tf.name_scope(\"Conditional\"):\n",
    "    LCconv1_1 = tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LInputQuery) \n",
    "    LCconv1_2 = tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LCconv1_1) \n",
    "    LCpool1 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(LCconv1_2)\n",
    "\n",
    "    \n",
    "    LCconv2_1 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LCpool1) \n",
    "    LCconv2_2 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LCconv2_1) \n",
    "    LCpool2 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(LCconv2_2)\n",
    "\n",
    "\n",
    "    LCconv3_1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LCpool2) \n",
    "    LCpool3 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(LCconv3_1)\n",
    "\n",
    "    \n",
    "    LCconv4_1 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LCpool3) \n",
    "    LCpool4 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(LCconv4_1)\n",
    "\n",
    "    \n",
    "    LCconv5_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LCpool4)  \n",
    "    LCpool5 = tf.keras.layers.MaxPool2D(pool_size=2, strides = 2, padding = 'SAME')(LCconv5_1)\n",
    "    \n",
    "    LCconv6_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 2, strides = 1, \n",
    "                   activation = tf.nn.relu)(LCpool5)\n",
    "    LCoutput = LCconv6_1\n",
    "    modelConditional = tf.keras.Model(inputs=LInputQuery, outputs=LCconv6_1, name=\"latent representation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConditional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(modelConditional, \"unet_encoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LInputIntermittent  = tf.keras.Input(dtype = tf.float32, shape = [8, 8, 1024], name = 'Encoded intermittent')\n",
    "with tf.name_scope(\"Transcoder\"):\n",
    "    LDtiling8x8 = tf.keras.layers.UpSampling2D(size=(8, 8))(LCoutput) # [1,1,512] -> [8,8,512]\n",
    "    LDconcat1_1 = tf.keras.layers.Concatenate(axis=-1)([Lpool5, LDtiling8x8]) # -> [8,8,1024]\n",
    "    LDdeconv1_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDconcat1_1) # [8,8,1024] -> [8,8,512]\n",
    "    LDdeconv1_2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDdeconv1_1)  # [8,8,512]  -> [8,8,512]\n",
    "    LDupsam1 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size = 3,\n",
    "                   strides=(2,2), padding='SAME', activation = tf.nn.relu)(LDdeconv1_2) # [8,8,512] -> [16,16,512]\n",
    "\n",
    "    \n",
    "    LDtiling16x16 = tf.keras.layers.UpSampling2D(size=(16, 16))(LCoutput) # [1,1,512] -> [16,16,512]\n",
    "    LDconcat2_1 = tf.keras.layers.Concatenate(axis=-1)([Lpool4, LDtiling16x16]) # -> [16,16,1024]\n",
    "    LDconv2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 1, strides = 1, padding='SAME',\n",
    "                   activation=tf.nn.relu)(LDconcat2_1) # [ 16, 16, 1024 ] -> [ 16, 16, 512 ]\n",
    "    LDconcat2_2 = tf.keras.layers.Concatenate(axis=-1)([LDupsam1, LDconv2]) # -> [ 16, 16, 1024 ]\n",
    "    LDdeconv2_1 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDconcat2_2) # [16,16,1024] -> [16,16,512]\n",
    "    LDdeconv2_2 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDdeconv2_1)  # [16,16,256]  -> [16,16,512]\n",
    "    LDupsam2 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size = 3,\n",
    "                   strides=(2,2), padding='SAME', activation = tf.nn.relu)(LDdeconv2_2) # [16,16,512] -> [32,32,512]\n",
    "    \n",
    "    \n",
    "    LDtiling32x32 = tf.keras.layers.UpSampling2D(size=(32, 32))(LCoutput) # [1,1,512] -> [32,32,512]\n",
    "    LDconcat3_1 = tf.keras.layers.Concatenate(axis=-1)([Lpool3, LDtiling32x32]) # -> [32,32,1024]\n",
    "    LDconv3 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 1, strides = 1, padding='SAME',\n",
    "                   activation=tf.nn.relu)(LDconcat3_1) # -> [32, 32, 256]\n",
    "    \n",
    "    LDconcat3_2 = tf.keras.layers.Concatenate(axis=-1)([LDupsam2, LDconv3]) # -> [32,32,768]\n",
    "    LDdeconv3_1 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDconcat3_2) # [32,32,768] -> [32,32,256]\n",
    "    LDdeconv3_2 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDdeconv3_1)  # [32,32,256]  -> [32,32,256]\n",
    "    LDupsam3 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size = 3,\n",
    "                   strides=(2,2), padding='SAME', activation = tf.nn.relu)(LDdeconv3_2) # -> [64,64,256]\n",
    "    \n",
    "    \n",
    "    LDtiling64x64 = tf.keras.layers.UpSampling2D(size=(64, 64))(LCoutput) # [1,1,512] -> [64,64,512]\n",
    "    LDconcat4_1 = tf.keras.layers.Concatenate(axis=-1)([Lpool2, LDtiling64x64]) # -> [64,64,768]\n",
    "    LDconv4 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 1, strides = 1, padding='SAME',\n",
    "                   activation=tf.nn.relu)(LDconcat4_1) # -> [64, 64, 128]\n",
    "    \n",
    "    LDconcat4_2 = tf.keras.layers.Concatenate(axis=-1)([LDupsam3, LDconv4]) # -> [64,64,384]\n",
    "    LDdeconv4_1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDconcat4_2) # [64,64,384] -> [64,64,128]\n",
    "    LDdeconv4_2 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDdeconv4_1)  # [64,64,128]  -> [64,64,128]\n",
    "    LDupsam4 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size = 3,\n",
    "                   strides=(2,2), padding='SAME', activation = tf.nn.relu)(LDdeconv4_2) # -> [128,128,128]\n",
    "    \n",
    "    \n",
    "    LDtiling128x128 = tf.keras.layers.UpSampling2D(size=(128, 128))(LCoutput) # [1,1,512] -> [128,128,512]\n",
    "    LDconcat5_1 = tf.keras.layers.Concatenate(axis=-1)([Lpool1, LDtiling128x128]) # -> [128,128,640]\n",
    "    LDconv5 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 1, strides = 1, padding='SAME',\n",
    "                   activation=tf.nn.relu)(LDconcat5_1) # -> [128, 128, 64]\n",
    "    \n",
    "    LDconcat5_2 = tf.keras.layers.Concatenate(axis=-1)([LDupsam4, LDconv5]) # -> [128,128,192]\n",
    "    LDdeconv5_1 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDconcat5_2) # [128,128,192] -> [128,128,64]\n",
    "    LDdeconv5_2 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu)(LDdeconv5_1)  # [128,128,64]  -> [128,128,64]\n",
    "    LDupsam5 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size = 3,\n",
    "                   strides=(2,2), padding='SAME', activation = tf.nn.relu)(LDdeconv5_2) # -> [256,256,64]\n",
    "    LDoutput = tf.keras.layers.Conv2D(filters = 1, kernel_size = 3, strides = 1, padding='SAME', \n",
    "                   activation = tf.nn.relu, name=\"Output\")(LDupsam5)  # [256,256,64]  -> [256,256,1]\n",
    "    modelUnet = tf.keras.Model(inputs=[LInputTarget, LInputQuery], outputs=[LDoutput], name=\"Unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelUnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(modelUnet, \"unet_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MASKS_PATH = '/qarr/studia/magister/datasets/FlickrLogos-v2/classes/masks/'\n",
    "INPUT_PATH = '/qarr/studia/magister/datasets/FlickrLogos-v2/classes/jpg/'\n",
    "\n",
    "classes = [o for o in os.listdir(INPUT_PATH) if os.path.isdir(INPUT_PATH + '/' + o)]\n",
    "classes = [o for o in classes if o != 'no-logo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytywanie obrazków do pamięci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = dict()\n",
    "targets = dict()\n",
    "queries = dict()\n",
    "start_time = time.time()\n",
    "\n",
    "def rescale(nparray, scale=255.0):\n",
    "    return np.array(nparray, dtype=np.float32)/scale\n",
    "\n",
    "for c in classes:\n",
    "    root_input = INPUT_PATH + '/' + c \n",
    "    root_masks = MASKS_PATH + '/' + c\n",
    "    images[c] = list()\n",
    "    targets[c] = list()\n",
    "    queries[c] = list()\n",
    "    \n",
    "    for f in os.listdir(root_input):\n",
    "        img = cv2.imread(f'{root_input}/{f}')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(f'{root_masks}/{f}.mask.merged.png', cv2.IMREAD_GRAYSCALE)\n",
    "        bboxes = []\n",
    "        \n",
    "        with open(f'{root_masks}/{f}.bboxes.txt') as csvfile:\n",
    "            bboxread = csv.reader(csvfile, delimiter=' ')\n",
    "            next(bboxread)\n",
    "            for row in bboxread:\n",
    "                bboxes.append(row)\n",
    "                \n",
    "        for bbox in bboxes:\n",
    "            x,y,w,h = [int(i) for i in bbox]\n",
    "            imgslice = img[y:y+h, x:x+w]\n",
    "            imgslice = cv2.resize(imgslice, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "            queries[c].append(rescale(imgslice, 255.0))\n",
    "            # Biore tylko pierwszy z dostepnych bbox na obrazku\n",
    "            break \n",
    "            \n",
    "        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        mask = cv2.resize(mask, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "        images[c].append(rescale(img, 255.0))\n",
    "        targets[c].append(rescale(mask, 255.0))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Time taken: {end_time-start_time} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generowanie listy labeli dla wczytanych obrazków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_labels = list()\n",
    "targets_labels = list()\n",
    "queries_labels = list()\n",
    "\n",
    "for c in classes:\n",
    "    images_labels += [classes.index(c)] * len(images[c])\n",
    "    queries_labels += [classes.index(c)] * len(queries[c])\n",
    "targets_labels = images_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytane przykłady obrazków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in images.values():\n",
    "    plt.imshow(v[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in targets.values():\n",
    "    plt.imshow(v[0], cmap='gist_gray')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in queries.values():\n",
    "    plt.imshow(v[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzenie tymczasowych datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumimgs = sum(images.values(), [])\n",
    "sumtargs = sum(targets.values(), [])\n",
    "sumquers = sum(queries.values(), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_dataset = tf.data.Dataset.from_tensor_slices((sumimgs, sumtargs, images_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queries_dataset = tf.data.Dataset.from_tensor_slices((sumquers, queries_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    print(f'{c:>12}: {len(images[c])} logos: {len(queries[c]):3<} pairs: {len(images[c])*len(queries[c])}')\n",
    "print(f'{\"total\":<12}: {sum([len(images[c]) for c in classes])} logos: {sum([len(queries[c]) for c in classes])} pairs: {sum([len(images[c])*len(queries[c]) for c in classes])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{32*(70*69)*(64*64*3+256*256*4)*8/1e9} GB vs {32*(70)*(64*64*3+256*256*4)*8/1e9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdyby brać pod uwagę każde logo z obrazka:\n",
    "```\n",
    "      adidas: 70 logos: 120 pairs: 8400\n",
    "        aldi: 70 logos: 106 pairs: 7420\n",
    "       apple: 70 logos: 76 pairs: 5320\n",
    "       becks: 70 logos: 100 pairs: 7000\n",
    "         bmw: 70 logos: 74 pairs: 5180\n",
    "   carlsberg: 70 logos: 108 pairs: 7560\n",
    "      chimay: 70 logos: 112 pairs: 7840\n",
    "    cocacola: 70 logos: 130 pairs: 9100\n",
    "      corona: 70 logos: 83 pairs: 5810\n",
    "         dhl: 70 logos: 123 pairs: 8610\n",
    "    erdinger: 70 logos: 105 pairs: 7350\n",
    "        esso: 70 logos: 87 pairs: 6090\n",
    "       fedex: 70 logos: 94 pairs: 6580\n",
    "     ferrari: 70 logos: 73 pairs: 5110\n",
    "        ford: 70 logos: 76 pairs: 5320\n",
    "     fosters: 70 logos: 98 pairs: 6860\n",
    "      google: 70 logos: 83 pairs: 5810\n",
    "     guiness: 70 logos: 98 pairs: 6860\n",
    "    heineken: 70 logos: 103 pairs: 7210\n",
    "          hp: 70 logos: 112 pairs: 7840\n",
    "       milka: 70 logos: 197 pairs: 13790\n",
    "      nvidia: 70 logos: 114 pairs: 7980\n",
    "    paulaner: 70 logos: 102 pairs: 7140\n",
    "       pepsi: 70 logos: 178 pairs: 12460\n",
    " rittersport: 70 logos: 204 pairs: 14280\n",
    "       shell: 70 logos: 96 pairs: 6720\n",
    "      singha: 70 logos: 83 pairs: 5810\n",
    "   starbucks: 70 logos: 95 pairs: 6650\n",
    "stellaartois: 70 logos: 87 pairs: 6090\n",
    "      texaco: 70 logos: 88 pairs: 6160\n",
    "    tsingtao: 70 logos: 109 pairs: 7630\n",
    "         ups: 70 logos: 90 pairs: 6300\n",
    "total       : 2240 logos: 3404 pairs: 238280\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_permutations_generator(batch_size):\n",
    "    nclasses = len(classes)\n",
    "    nlogos = sum([len(images[c]) for c in classes])//nclasses\n",
    "    data_permutations = np.zeros((nclasses*nlogos*(nlogos-1), 3), dtype=np.int8)\n",
    "    i = 0\n",
    "    for c_i in range(nclasses):\n",
    "        for n_i in range(nlogos):\n",
    "            for l_i in range(nlogos):\n",
    "                if n_i == l_i:\n",
    "                    continue\n",
    "                data_permutations[i] = (c_i, n_i, l_i)\n",
    "                i += 1\n",
    "    data_permutations = np.random.permutation(data_permutations)\n",
    "    s = 0\n",
    "    outimage = []\n",
    "    outquery = []\n",
    "    outtarget = []\n",
    "    for class_number, image_number, query_number in data_permutations:\n",
    "        c = classes[class_number]\n",
    "        outimage.append(images[c][image_number])\n",
    "        outquery.append(queries[c][query_number])\n",
    "        outtarget.append(targets[c][image_number])\n",
    "        s += 1\n",
    "        if s >= batch_size:\n",
    "            s = 0\n",
    "            yield (np.reshape(outimage, (batch_size, 256, 256, 3)),\n",
    "                   np.reshape(outquery, (batch_size, 64, 64, 3))\n",
    "                  ), np.reshape(outtarget, (batch_size, 256, 256, 1))\n",
    "            outimage = []\n",
    "            outquery = []\n",
    "            outtarget = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test generatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testgen = dataset_permutations_generator(1)\n",
    "tdat = next(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tdat[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "unetDataset = tf.data.Dataset.from_generator(dataset_permutations_generator,\n",
    "                                             args=[batch_size],\n",
    "                                             output_types=((tf.float32, tf.float32), tf.float32),\n",
    "                                             output_shapes=(((batch_size, 256,256,3), (batch_size, 64,64,3)),\n",
    "                                                          (batch_size, 256,256,1))\n",
    "                                            )\n",
    "#unetDataset = unetDataset.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zestawienie modelu i uczenie - próba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0004, momentum=0.9, nesterov=False, name=\"SGD\") # weight decay 0.0005\n",
    "\n",
    "modelUnet.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#modelUnet.fit(unetDataset, epochs=1, steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_inst = dataset_permutations_generator(32)\n",
    "custom_batch = [next(gen_inst) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    try:\n",
    "        return f'{x.shape}'\n",
    "    except AttributeError:\n",
    "        return f\"{'[' + ', '.join([describe(q) for q in x]) + ']'}\"\n",
    "\n",
    "\n",
    "#custom_batch[0]\n",
    "print(describe(custom_batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = tf.data.Dataset.from_tensors(custom_batch[0])\n",
    "#testDataset = testDataset.batch(32)\n",
    "#timgs, tquers, ttargs = ([a for a,b,c in custom_batch], [b for a,b,c in custom_batch], [c for a,b,c in custom_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = custom_batch[0][0][0]\n",
    "qry = custom_batch[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(qry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelUnet.predict({\"Target\":img, \"Query\":qry})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in testDataset]\n",
    "a = a[0]\n",
    "a[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelUnet.fit(testDataset, epochs=1, steps_per_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
